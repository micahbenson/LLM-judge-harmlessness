# LLM-judge-harmlessness
NLP final project 

527A Final Project
Researching the ability of LLMs to judge bias in their own outputs
